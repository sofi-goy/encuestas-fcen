{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "BASE = \"https://encuestas-finales.exactas.uba.ar/\"\n",
    "INICIO = BASE + \"periodos.html\"\n",
    "\n",
    "soup = bs(requests.get(INICIO).text, \"html.parser\")\n",
    "\n",
    "ordinales = {\"1\": \"Primer\", \"2\": \"Segundo\", \"3\": \"Tercero\", \"4\":\"Cuarto\"}\n",
    "epocas = {\"i\": \"Invierno\", \"v\": \"Verano\", \"c\": \"Cuatrimestre\", \"b\": \"Bimestre\"}\n",
    "\n",
    "def lst(lid, p):\n",
    "    print(\"LST\", lid, p)\n",
    "    url = BASE + \"lists/l_\"  + lid + \"_\" + p + \".html\"\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "def parsear_periodo(periodo):\n",
    "    if len(periodo) == 5:\n",
    "        if periodo[0] == \"a\":\n",
    "            return\n",
    "\n",
    "        epoca = epocas[periodo[0]]\n",
    "        año = periodo[1:]\n",
    "    \n",
    "    elif len(periodo) == 6:\n",
    "        epoca = ordinales[periodo[0]] + \" \" + epocas[periodo[1]]\n",
    "        año = periodo[2:]\n",
    "\n",
    "    else:\n",
    "        print(\"Error en el formato del periodo\", periodo)\n",
    "        return\n",
    "\n",
    "    return epoca, año\n",
    "    # data = []\n",
    "    # soup = bs(requests.get(url).text, \"html.parser\")\n",
    "    # paginas = soup.find_all(\"div\", class_=\"list\")[0]\n",
    "    # id_ = paginas.attrs[\"id\"].split(\"_\")[-1]\n",
    "    # links = paginas.find_all(\"div\", class_=\"head\")[0].find_all(\"a\")\n",
    "    # for link in links:\n",
    "    #     p = link.text\n",
    "    #     lst(id_, p)\n",
    "    \n",
    "\n",
    "# encuestas = []\n",
    "# for fila in soup.find_all(\"tr\"):\n",
    "#     if fila.find(\"th\"):\n",
    "#         continue\n",
    "#     periodo = fila.find_all(\"td\")[0].text\n",
    "#     url = BASE + fila.find_all(\"td\")[1].find(\"a\")[\"href\"]\n",
    "#     if periodo == \"2c2022\":\n",
    "#         parsear_periodo(periodo, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LST mats 0\n",
      "LST mats 1\n",
      "LST mats 2\n",
      "LST mats 3\n",
      "LST mats 4\n",
      "LST mats 5\n",
      "LST mats 6\n",
      "LST mats 7\n",
      "LST mats 8\n",
      "LST mats 9\n",
      "LST mats 10\n",
      "LST mats 11\n",
      "LST mats 12\n",
      "LST mats 13\n",
      "LST mats 14\n",
      "LST mats 15\n",
      "LST mats 16\n",
      "LST mats 17\n",
      "LST mats 18\n",
      "LST mats 19\n",
      "LST mats 20\n",
      "LST mats 21\n",
      "LST mats 22\n",
      "LST mats 23\n",
      "LST mats 24\n",
      "LST mats 25\n",
      "LST mats 26\n",
      "LST mats 27\n",
      "LST mats 28\n",
      "LST mats 29\n",
      "LST mats 30\n",
      "LST mats 31\n",
      "LST mats 32\n",
      "LST mats 33\n",
      "LST mats 34\n",
      "LST mats 35\n",
      "LST mats 36\n",
      "LST mats 37\n",
      "LST mats 38\n",
      "LST mats 39\n",
      "LST mats 40\n",
      "LST mats 41\n",
      "LST mats 42\n",
      "LST mats 43\n",
      "LST mats 44\n",
      "LST mats 45\n",
      "LST mats 46\n",
      "LST mats 47\n",
      "LST mats 48\n",
      "LST mats 49\n",
      "LST mats 50\n",
      "LST mats 51\n",
      "LST mats 52\n",
      "LST mats 53\n",
      "LST mats 54\n",
      "LST mats 55\n",
      "LST mats 56\n",
      "LST mats 57\n",
      "LST mats 58\n",
      "LST mats 59\n",
      "LST mats 60\n",
      "LST mats 61\n",
      "LST mats 62\n",
      "LST mats 63\n",
      "LST mats 64\n",
      "LST mats 65\n",
      "LST mats 66\n",
      "LST mats 67\n",
      "LST mats 68\n",
      "LST mats 69\n",
      "LST mats 70\n",
      "LST mats 71\n",
      "LST mats 72\n",
      "LST mats 73\n"
     ]
    }
   ],
   "source": [
    "def parsear_materias():\n",
    "    PAGINAS = 74\n",
    "    materias = {}\n",
    "    for i in range(PAGINAS):\n",
    "        html = lst(\"mats\", str(i))\n",
    "        for materia in bs(html, \"html.parser\").find(\"ul\").find_all(\"li\"):\n",
    "            # Save materia withthetext as a key and the link as a value\n",
    "            link = materia.find(\"a\")\n",
    "            materias[link.text] = BASE + link[\"href\"]\n",
    "\n",
    "    import json\n",
    "    with open(\"materias.json\", \"w\") as f:\n",
    "        json.dump(materias, f)\n",
    "\n",
    "parsear_materias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisis de Datos ('Primer Cuatrimestre', '2008')\n",
      "Analisis de Datos ('Primer Cuatrimestre', '2006')\n",
      "Analisis de Datos ('Segundo Cuatrimestre', '2003')\n",
      "Acoplamiento y Procesos Estocasticos ('Segundo Cuatrimestre', '2004')\n",
      "Acuaporinas:estructura y Funcion ('Segundo Cuatrimestre', '2012')\n",
      "Administracion de Proyectos Informaticos ('Segundo Cuatrimestre', '2011')\n",
      "Administracion de Proyectos Informaticos ('Segundo Cuatrimestre', '2010')\n",
      "Administracion de Proyectos Informaticos ('Primer Cuatrimestre', '2006')\n",
      "Administracion de Proyectos Informaticos ('Segundo Cuatrimestre', '2005')\n",
      "Administracion de Proyectos Informaticos ('Primer Cuatrimestre', '2005')\n",
      "Administracion de Proyectos Informaticos ('Segundo Cuatrimestre', '2004')\n",
      "Administracion de Proyectos Informaticos ('Primer Cuatrimestre', '2004')\n",
      "Administracion de Proyectos Informaticos ('Segundo Cuatrimestre', '2003')\n",
      "Administracion de Proyectos Informaticos ('Primer Cuatrimestre', '2003')\n",
      "Administracion de Proyectos Informaticos ('Segundo Cuatrimestre', '2002')\n",
      "Administracion de Proyectos Informaticos ('Primer Cuatrimestre', '2002')\n",
      "Advanced Fluorescence Microscopy Techniques.dynamis Through The Microscope Fluorescence Correlation ('Segundo Cuatrimestre', '2007')\n",
      "Advances In Technologies For High Resolutions In Vivo Microscopy. ('Segundo Cuatrimestre', '2006')\n",
      "Agrometeorologia y Desarrollo Sustentable ('Segundo Cuatrimestre', '2010')\n",
      "Aguas Continentales ('Segundo Cuatrimestre', '2004')\n",
      "Aleman Cientifico y Tecnico None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m encuestas \u001b[39m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m materia, url \u001b[39min\u001b[39;00m materias\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 86\u001b[0m     encuestas \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m  parsear_materia(materia, url)\n\u001b[1;32m     88\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m     89\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(encuestas)\n",
      "Cell \u001b[0;32mIn[105], line 75\u001b[0m, in \u001b[0;36mparsear_materia\u001b[0;34m(materia, url)\u001b[0m\n\u001b[1;32m     69\u001b[0m     respuestas \u001b[39m=\u001b[39m parsear_respuestas(BASE \u001b[39m+\u001b[39m foto_url)\n\u001b[1;32m     70\u001b[0m     comentarios \u001b[39m=\u001b[39m parsear_comentarios(id_materia, id_cuatri)\n\u001b[1;32m     72\u001b[0m     encuestas\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     73\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmateria\u001b[39m\u001b[39m\"\u001b[39m: materia,\n\u001b[1;32m     74\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdepartamento\u001b[39m\u001b[39m\"\u001b[39m: departamento,\n\u001b[0;32m---> 75\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mepoca\u001b[39m\u001b[39m\"\u001b[39m: periodo[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m     76\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maño\u001b[39m\u001b[39m\"\u001b[39m: periodo[\u001b[39m1\u001b[39m],\n\u001b[1;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcomentarios\u001b[39m\u001b[39m\"\u001b[39m: comentarios,\n\u001b[1;32m     78\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrespuestas\n\u001b[1;32m     79\u001b[0m     })\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m encuestas\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import hashlib\n",
    "materias = json.load(open(\"materias.json\"))\n",
    "\n",
    "respuestas_hash = {}\n",
    "\n",
    "def parsear_periodo(periodo):\n",
    "    if len(periodo) == 5:\n",
    "        if periodo[0] == \"a\":\n",
    "            return None, None\n",
    "\n",
    "        epoca = epocas[periodo[0]]\n",
    "        año = periodo[1:]\n",
    "    \n",
    "    elif len(periodo) == 6:\n",
    "        epoca = ordinales[periodo[0]] + \" \" + epocas[periodo[1]]\n",
    "        año = periodo[2:]\n",
    "\n",
    "    else:\n",
    "        print(\"Error en el formato del periodo\", periodo)\n",
    "        return None, None\n",
    "\n",
    "    return epoca, año\n",
    "\n",
    "def parsear_respuestas(url):\n",
    "    global respuestas_hash\n",
    "    PREGUNTAS = 17\n",
    "    imagen = requests.get(url).content\n",
    "    with open(\"/tmp/respuestas_exactas.png\", \"wb\") as f:\n",
    "        f.write(imagen)\n",
    "\n",
    "    img = cv2.imread(\"/tmp/respuestas_exactas.png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    width = img.shape[1]\n",
    "    width_res = width // PREGUNTAS + 1\n",
    "\n",
    "    respuestas = {}\n",
    "    for i in range(PREGUNTAS-1):\n",
    "        respuesta = img[:,width_res*i:width_res*(i+1)-1]\n",
    "        hasheada = hashlib.md5(respuesta.data.tobytes()).hexdigest()\n",
    "        if not hasheada in respuestas_hash:\n",
    "            respuestas_hash[hasheada] = respuesta\n",
    "            cv2.imwrite(f\"respuestas/{hasheada}.png\", respuesta)   \n",
    "\n",
    "        respuestas[f\"p{i}\"] = hasheada\n",
    "    \n",
    "    return respuestas\n",
    "\n",
    "def parsear_comentarios(id_materia, id_cuatri):\n",
    "    url = BASE + \"cma/\" + id_materia + id_cuatri + \".html\"\n",
    "    soup = bs(requests.get(url).text, \"html.parser\")\n",
    "    \n",
    "    comentarios = []\n",
    "    for comentario in soup.find_all(\"div\", class_=\"cm\"):\n",
    "        comentarios.append(comentario.text.replace('\\r', '\\n'))\n",
    "\n",
    "    return comentarios\n",
    "\n",
    "def parsear_materia(materia, url):\n",
    "    soup = bs(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "    id_materia = url.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    departamento = None\n",
    "    encuestas = []\n",
    "    \n",
    "    for bold in soup.find_all(\"b\"):\n",
    "        if bold.text == \"Departamento:\":\n",
    "            departamento = bold.next_sibling.next_sibling.text\n",
    "    \n",
    "    # Find tr elements with non empty ids and withoout  display none\n",
    "    for fila in soup.find_all(\"tr\"):\n",
    "        if not fila.has_attr(\"id\"):\n",
    "            continue\n",
    "        if fila.has_attr(\"style\"):\n",
    "            continue\n",
    "\n",
    "        id_cuatri = fila.attrs[\"id\"]\n",
    "        periodo = fila.find_all(\"td\")[0].text\n",
    "        periodo = parsear_periodo(periodo)\n",
    "        foto_url = '/'.join(fila.find(\"img\")[\"src\"].split(\"/\")[1:])\n",
    "        print(materia, periodo)\n",
    "\n",
    "        respuestas = parsear_respuestas(BASE + foto_url)\n",
    "        comentarios = parsear_comentarios(id_materia, id_cuatri)\n",
    "\n",
    "        encuestas.append({\n",
    "            \"materia\": materia,\n",
    "            \"departamento\": departamento,\n",
    "            \"epoca\": periodo[0],\n",
    "            \"año\": periodo[1],\n",
    "            \"comentarios\": comentarios,\n",
    "            **respuestas\n",
    "        })\n",
    "    \n",
    "    return encuestas\n",
    "        \n",
    "\n",
    "encuestas = []\n",
    "for materia, url in materias.items():\n",
    "    encuestas +=  parsear_materia(materia, url)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(encuestas)\n",
    "df.to_csv(\"encuestas.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
